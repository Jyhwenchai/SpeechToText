import Testing
import Foundation
@testable import SpeechToTextKit

/// çœŸå®éŸ³é¢‘æ–‡ä»¶æµ‹è¯•
/// 
/// æµ‹è¯•å®é™…éŸ³é¢‘æ–‡ä»¶çš„è¯­éŸ³è¯†åˆ«å’Œæ ‡ç‚¹ç¬¦å·æ¢å¤åŠŸèƒ½
struct RealAudioTests {
  
  /// æµ‹è¯•å¤è¯—è¯éŸ³é¢‘ï¼šåºŠå‰æ˜æœˆå…‰
  @Test("çœŸå®éŸ³é¢‘æµ‹è¯•ï¼šåºŠå‰æ˜æœˆå…‰ï¼ˆè¯—è¯æ¨¡å¼ï¼‰")
  func testRealAudio_Poetry() async throws {
    // éŸ³é¢‘æ–‡ä»¶è·¯å¾„
    let audioPath = "/Users/didong/Desktop/work/project/SpeechToText/Example-UIKit/Example-UIKit/test.m4a"
    let audioURL = URL(fileURLWithPath: audioPath)
    
    // æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    guard FileManager.default.fileExists(atPath: audioPath) else {
      Issue.record("éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: \(audioPath)")
      return
    }
    
    print("ğŸ“ éŸ³é¢‘æ–‡ä»¶è·¯å¾„: \(audioPath)")
    
    // åˆ›å»ºè¯­éŸ³è¯†åˆ«é…ç½®ï¼ˆä¸­æ–‡ + è¯—è¯æ–­å¥ï¼‰
    let config = RecognitionConfig(
      locale: Locale(identifier: "zh-CN"),
      requiresOnDeviceRecognition: false,
      taskHint: .dictation,
      punctuationRecovery: .poetry  // ä½¿ç”¨è¯—è¯æ¨¡å¼
    )
    
    // åˆ›å»ºè¯­éŸ³è½¬æ–‡æœ¬å®ä¾‹
    let transcriber = SpeechFileTranscriber(config: config)
    
    print("ğŸ¤ å¼€å§‹è¯†åˆ«éŸ³é¢‘...")
    
    // æ‰§è¡Œè¯­éŸ³è¯†åˆ«
    let result = try await transcriber.transcribe(audioURL: audioURL)
    
    print("ğŸ“ è¯†åˆ«ç»“æœ:")
    print("  - åŸå§‹æ–‡æœ¬: \(result.formattedText)")
    print("  - æ—¶é—´ç‰‡æ®µæ•°é‡: \(result.segments.count)")
    
    // æ‰“å°æ¯ä¸ªæ—¶é—´ç‰‡æ®µçš„è¯¦ç»†ä¿¡æ¯
    for (index, segment) in result.segments.enumerated() {
      print("  [\(index)] \(String(format: "%.2f", segment.start))-\(String(format: "%.2f", segment.end))s: \(segment.text)")
    }
    
    // éªŒè¯ç»“æœ
    #expect(!result.formattedText.isEmpty, "è¯†åˆ«æ–‡æœ¬ä¸åº”ä¸ºç©º")
    
    // éªŒè¯æ˜¯å¦åŒ…å«å…³é”®è¯
    let keywords = ["åºŠå‰", "æ˜æœˆ", "ç–‘æ˜¯", "åœ°ä¸Šéœœ", "ä¸¾å¤´", "ä½å¤´", "æ•…ä¹¡"]
    var foundKeywords = 0
    for keyword in keywords {
      if result.formattedText.contains(keyword) {
        foundKeywords += 1
      }
    }
    
    print("âœ… æ‰¾åˆ°å…³é”®è¯æ•°é‡: \(foundKeywords)/\(keywords.count)")
    #expect(foundKeywords >= 5, "åº”è¯¥è¯†åˆ«å‡ºè‡³å°‘5ä¸ªå…³é”®è¯")
    
    // éªŒè¯æ˜¯å¦æ·»åŠ äº†æ ‡ç‚¹ç¬¦å·
    let hasPunctuation = result.formattedText.contains("ï¼Œ") || 
                        result.formattedText.contains("ã€‚") ||
                        result.formattedText.contains(",") ||
                        result.formattedText.contains(".")
    
    print("ğŸ“Œ æ ‡ç‚¹ç¬¦å·æ£€æµ‹: \(hasPunctuation ? "âœ… å·²æ·»åŠ " : "âŒ æœªæ·»åŠ ")")
    #expect(hasPunctuation, "åº”è¯¥åŒ…å«æ ‡ç‚¹ç¬¦å·")
    
    print("\nğŸ¯ æœ€ç»ˆæ ¼å¼åŒ–æ–‡æœ¬:")
    print("   \(result.formattedText)")
  }
  
  /// æµ‹è¯•å¤è¯—è¯éŸ³é¢‘ï¼šçº¯è¯­ä¹‰æ¨¡å¼
  @Test("çœŸå®éŸ³é¢‘æµ‹è¯•ï¼šåºŠå‰æ˜æœˆå…‰ï¼ˆçº¯è¯­ä¹‰æ¨¡å¼ï¼‰")
  func testRealAudio_SemanticOnly() async throws {
    let audioPath = "/Users/didong/Desktop/work/project/SpeechToText/Example-UIKit/Example-UIKit/test.m4a"
    let audioURL = URL(fileURLWithPath: audioPath)
    
    guard FileManager.default.fileExists(atPath: audioPath) else {
      Issue.record("éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: \(audioPath)")
      return
    }
    
    print("ğŸ“ éŸ³é¢‘æ–‡ä»¶è·¯å¾„: \(audioPath)")
    
    // ä½¿ç”¨çº¯è¯­ä¹‰æ¨¡å¼
    let config = RecognitionConfig(
      locale: Locale(identifier: "zh-CN"),
      requiresOnDeviceRecognition: false,
      taskHint: .dictation,
      punctuationRecovery: .semanticOnly
    )
    
    let transcriber = SpeechFileTranscriber(config: config)
    
    print("ğŸ¤ å¼€å§‹è¯†åˆ«éŸ³é¢‘ï¼ˆçº¯è¯­ä¹‰æ¨¡å¼ï¼‰...")
    
    let result = try await transcriber.transcribe(audioURL: audioURL)
    
    print("ğŸ“ è¯†åˆ«ç»“æœ:")
    print("  - æ ¼å¼åŒ–æ–‡æœ¬: \(result.formattedText)")
    print("  - æ—¶é—´ç‰‡æ®µæ•°é‡: \(result.segments.count)")
    
    // éªŒè¯æ ‡ç‚¹ç¬¦å·
    let punctuationCount = result.formattedText.filter { "ï¼Œã€‚,.".contains($0) }.count
    print("ğŸ“Œ æ ‡ç‚¹ç¬¦å·æ•°é‡: \(punctuationCount)")
    
    #expect(punctuationCount > 0, "çº¯è¯­ä¹‰æ¨¡å¼åº”è¯¥æ·»åŠ æ ‡ç‚¹ç¬¦å·")
    
    print("\nğŸ¯ æœ€ç»ˆæ ¼å¼åŒ–æ–‡æœ¬:")
    print("   \(result.formattedText)")
  }
  
  /// æµ‹è¯•å¯¹æ¯”ï¼šä¸åŒé…ç½®çš„æ•ˆæœ
  @Test("å¯¹æ¯”æµ‹è¯•ï¼šæ ‡å‡†æ¨¡å¼ vs è¯—è¯æ¨¡å¼ vs çº¯è¯­ä¹‰æ¨¡å¼")
  func testComparison_AllModes() async throws {
    let audioPath = "/Users/didong/Desktop/work/project/SpeechToText/Example-UIKit/Example-UIKit/test.m4a"
    let audioURL = URL(fileURLWithPath: audioPath)
    
    guard FileManager.default.fileExists(atPath: audioPath) else {
      Issue.record("éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: \(audioPath)")
      return
    }
    
    print("\n" + String(repeating: "=", count: 60))
    print("ğŸ”¬ å¯¹æ¯”æµ‹è¯•ï¼šä¸åŒæ ‡ç‚¹æ¢å¤æ¨¡å¼")
    print(String(repeating: "=", count: 60))
    
    // é…ç½®1ï¼šæ ‡å‡†æ¨¡å¼
    print("\n1ï¸âƒ£  æ ‡å‡†æ¨¡å¼ (.default)")
    print(String(repeating: "-", count: 60))
    let config1 = RecognitionConfig(
      locale: Locale(identifier: "zh-CN"),
      punctuationRecovery: .default
    )
    let transcriber1 = SpeechFileTranscriber(config: config1)
    let result1 = try await transcriber1.transcribe(audioURL: audioURL)
    print("ç»“æœ: \(result1.formattedText)")
    print("æ ‡ç‚¹æ•°: \(result1.formattedText.filter { "ï¼Œã€‚".contains($0) }.count)")
    
    // é…ç½®2ï¼šè¯—è¯æ¨¡å¼
    print("\n2ï¸âƒ£  è¯—è¯æ¨¡å¼ (.poetry)")
    print(String(repeating: "-", count: 60))
    let config2 = RecognitionConfig(
      locale: Locale(identifier: "zh-CN"),
      punctuationRecovery: .poetry
    )
    let transcriber2 = SpeechFileTranscriber(config: config2)
    let result2 = try await transcriber2.transcribe(audioURL: audioURL)
    print("ç»“æœ: \(result2.formattedText)")
    print("æ ‡ç‚¹æ•°: \(result2.formattedText.filter { "ï¼Œã€‚".contains($0) }.count)")
    
    // é…ç½®3ï¼šçº¯è¯­ä¹‰æ¨¡å¼
    print("\n3ï¸âƒ£  çº¯è¯­ä¹‰æ¨¡å¼ (.semanticOnly)")
    print(String(repeating: "-", count: 60))
    let config3 = RecognitionConfig(
      locale: Locale(identifier: "zh-CN"),
      punctuationRecovery: .semanticOnly
    )
    let transcriber3 = SpeechFileTranscriber(config: config3)
    let result3 = try await transcriber3.transcribe(audioURL: audioURL)
    print("ç»“æœ: \(result3.formattedText)")
    print("æ ‡ç‚¹æ•°: \(result3.formattedText.filter { "ï¼Œã€‚".contains($0) }.count)")
    
    print("\n" + String(repeating: "=", count: 60))
    print("ğŸ“Š å¯¹æ¯”æ€»ç»“")
    print(String(repeating: "=", count: 60))
    print("æ ‡å‡†æ¨¡å¼æ ‡ç‚¹æ•°: \(result1.formattedText.filter { "ï¼Œã€‚".contains($0) }.count)")
    print("è¯—è¯æ¨¡å¼æ ‡ç‚¹æ•°: \(result2.formattedText.filter { "ï¼Œã€‚".contains($0) }.count)")
    print("è¯­ä¹‰æ¨¡å¼æ ‡ç‚¹æ•°: \(result3.formattedText.filter { "ï¼Œã€‚".contains($0) }.count)")
    
    // éªŒè¯ï¼šè¯—è¯æ¨¡å¼å’Œè¯­ä¹‰æ¨¡å¼åº”è¯¥æ¯”æ ‡å‡†æ¨¡å¼æ·»åŠ æ›´å¤šæ ‡ç‚¹
    let standardPunctCount = result1.formattedText.filter { "ï¼Œã€‚".contains($0) }.count
    let poetryPunctCount = result2.formattedText.filter { "ï¼Œã€‚".contains($0) }.count
    let semanticPunctCount = result3.formattedText.filter { "ï¼Œã€‚".contains($0) }.count
    
    print("\nâœ… éªŒè¯ç»“æœ:")
    print("  - è¯—è¯æ¨¡å¼ä¼˜äºæ ‡å‡†æ¨¡å¼: \(poetryPunctCount >= standardPunctCount ? "âœ“" : "âœ—")")
    print("  - è¯­ä¹‰æ¨¡å¼ä¼˜äºæ ‡å‡†æ¨¡å¼: \(semanticPunctCount >= standardPunctCount ? "âœ“" : "âœ—")")
    
    #expect(poetryPunctCount >= standardPunctCount, "è¯—è¯æ¨¡å¼åº”è¯¥æ·»åŠ â‰¥æ ‡å‡†æ¨¡å¼çš„æ ‡ç‚¹")
    #expect(semanticPunctCount >= standardPunctCount, "è¯­ä¹‰æ¨¡å¼åº”è¯¥æ·»åŠ â‰¥æ ‡å‡†æ¨¡å¼çš„æ ‡ç‚¹")
  }
  
  /// æ‰‹åŠ¨æµ‹è¯•è¾…åŠ©å‡½æ•°ï¼šæ‰“å°è¯¦ç»†çš„ segments ä¿¡æ¯
  @Test("è°ƒè¯•ï¼šæ‰“å°è¯¦ç»† segments ä¿¡æ¯")
  func testDebug_PrintSegments() async throws {
    let audioPath = "/Users/didong/Desktop/work/project/SpeechToText/Example-UIKit/Example-UIKit/test.m4a"
    let audioURL = URL(fileURLWithPath: audioPath)
    
    guard FileManager.default.fileExists(atPath: audioPath) else {
      Issue.record("éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: \(audioPath)")
      return
    }
    
    let config = RecognitionConfig(
      locale: Locale(identifier: "zh-CN"),
      punctuationRecovery: nil  // ä¸ä½¿ç”¨æ ‡ç‚¹æ¢å¤ï¼Œè·å–åŸå§‹è¯†åˆ«ç»“æœ
    )
    
    let transcriber = SpeechFileTranscriber(config: config)
    let result = try await transcriber.transcribe(audioURL: audioURL)
    
    print("\n" + String(repeating: "=", count: 80))
    print("ğŸ” è¯¦ç»† Segments åˆ†æ")
    print(String(repeating: "=", count: 80))
    print("æ€»ç‰‡æ®µæ•°: \(result.segments.count)")
    print("åŸå§‹æ–‡æœ¬: \(result.formattedText)")
    print(String(repeating: "-", count: 80))
    
    for (index, segment) in result.segments.enumerated() {
      let gap = index < result.segments.count - 1 
        ? result.segments[index + 1].start - segment.end 
        : 0
      
      print("[\(String(format: "%2d", index))] " +
            "æ—¶é—´: \(String(format: "%5.2f", segment.start))s - \(String(format: "%5.2f", segment.end))s " +
            "| æ—¶é•¿: \(String(format: "%.2f", segment.end - segment.start))s " +
            "| é—´éš”: \(String(format: "%.2f", gap))s " +
            "| æ–‡æœ¬: \"\(segment.text)\"")
    }
    
    print(String(repeating: "=", count: 80))
    
    // ä½¿ç”¨è¿™äº›ä¿¡æ¯æ‰‹åŠ¨æµ‹è¯• TextFormatter
    print("\nğŸ§ª æ‰‹åŠ¨åº”ç”¨æ ‡ç‚¹æ¢å¤ï¼ˆè¯—è¯æ¨¡å¼ï¼‰:")
    
    let segments = result.segments.map { segment in
      TextFormatter.SegmentProxy(
        text: segment.text,
        start: segment.start,
        end: segment.end
      )
    }
    
    let formattedResult = TextFormatter.formatSync(
      text: result.formattedText,
      segments: segments,
      options: .poetry
    )
    
    print("æ ¼å¼åŒ–å: \(formattedResult)")
  }
}
